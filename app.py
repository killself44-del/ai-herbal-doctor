import streamlit as st
import os
import requests
import json
from pinecone import Pinecone
from dotenv import load_dotenv
import db  # ğŸ“‚ êµ¬ê¸€ ì‹œíŠ¸ ëª¨ë“ˆ (ì‚¬ìš©ìë‹˜ ê¸°ì¡´ íŒŒì¼ ìœ ì§€)

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()

# 2. ì•ˆì „í•œ í‚¤ ê°€ì ¸ì˜¤ê¸°
def get_secret(key_name):
    try:
        if key_name in st.secrets: return st.secrets[key_name]
    except: pass
    return os.getenv(key_name)

GOOGLE_API_KEY = get_secret("GOOGLE_API_KEY")
PINECONE_API_KEY = get_secret("PINECONE_API_KEY")

if not GOOGLE_API_KEY or not PINECONE_API_KEY:
    st.error("ğŸš¨ API í‚¤ ì—ëŸ¬")
    st.stop()

# Pinecone & Model ì„¤ì •
pc = Pinecone(api_key=PINECONE_API_KEY)
index_name = "herb-knowledge"
index = pc.Index(index_name)

GEMINI_EMBED_MODEL = "models/text-embedding-004"
GEMINI_GEN_MODEL = "gemini-2.0-flash-exp"

# --- í•µì‹¬ í•¨ìˆ˜: ê²€ìƒ‰ (AI ìƒê° ëºŒ) ---
def get_gemini_embedding(text):
    # 'RETRIEVAL_QUERY'ë¡œ ì„¤ì •í•˜ì—¬ ê²€ìƒ‰ ìµœì í™”
    url = f"https://generativelanguage.googleapis.com/v1beta/{GEMINI_EMBED_MODEL}:embedContent?key={GOOGLE_API_KEY}"
    payload = {
        "model": GEMINI_EMBED_MODEL,
        "content": {"parts": [{"text": text}]},
        "taskType": "RETRIEVAL_QUERY"
    }
    try:
        response = requests.post(url, json=payload)
        return response.json()['embedding']['values']
    except:
        return None

def retrieve_context(user_symptom, top_k=5):
    try:
        # âš¡ï¸ [ìˆ˜ì •] AIì—ê²Œ ê²€ìƒ‰ì–´ë¥¼ ë‹¤ì‹œ ë§Œë“¤ë¼ê³  ì‹œí‚¤ì§€ ì•Šê³ , 
        # ì‚¬ìš©ìê°€ ë§í•œ ì¦ìƒì„ ê·¸ëŒ€ë¡œ ë„£ë˜, 'ë¬¸ë§¥'ë§Œ ì‚´ì§ ì¶”ê°€í•©ë‹ˆë‹¤.
        query_text = f"ì¦ìƒ '{user_symptom}'ì„ ì¹˜ë£Œí•˜ëŠ” ì•½ì´ˆì˜ íš¨ëŠ¥ê³¼ ì‚¬ìš©ë²•"
        
        embedding = get_gemini_embedding(query_text)
        if not embedding: return ""
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = index.query(
            vector=embedding,
            top_k=top_k,
            include_metadata=True
        )
        
        # ê²°ê³¼ ì •ë¦¬
        contexts = []
        for match in results['matches']:
            meta = match['metadata']
            # ì´ë¦„ê³¼ íš¨ëŠ¥ì„ ê°€ì ¸ì˜´
            text = f"ì•½ì´ˆëª…: {meta.get('name')}\níš¨ëŠ¥: {meta.get('efficacy')}\nì£¼ì˜ì‚¬í•­: {meta.get('caution')}"
            contexts.append(text)
            
        return "\n\n".join(contexts)
    except Exception as e:
        return f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}"

def generate_diagnosis(messages, retrieved_info):
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_GEN_MODEL}:generateContent?key={GOOGLE_API_KEY}"
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ê²€ìƒ‰ëœ ì •ë³´ë§Œ ê°€ì§€ê³  ë‹µí•˜ê²Œ ê°•ì œí•¨
    system_prompt = f"""
    ë‹¹ì‹ ì€ ì•½ì´ˆ ì²˜ë°© ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì•„ë˜ [ê²€ìƒ‰ëœ ì•½ì´ˆ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™˜ìì˜ ì¦ìƒì— ë§ëŠ” ì•½ì„ ì¶”ì²œí•˜ì„¸ìš”.
    
    [ê²€ìƒ‰ëœ ì•½ì´ˆ ì •ë³´]
    {retrieved_info}
    
    [ì£¼ì˜ì‚¬í•­]
    1. ë°˜ë“œì‹œ ìœ„ **ê²€ìƒ‰ëœ ì •ë³´ì— ìˆëŠ” ì•½ì´ˆ** ì¤‘ì—ì„œë§Œ ì¶”ì²œí•˜ì„¸ìš”.
    2. 'í˜¸ìœ 'ë‚˜ 'íŒŒìŠ¬ë¦¬'ê°€ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ë‹¤ë©´ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
    3. í™˜ìì˜ ì¦ìƒê³¼ ê°€ì¥ ì˜ ë§ëŠ” ì•½ì´ˆ 1~2ê°€ì§€ë¥¼ ê³¨ë¼ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
    """
    
    formatted_contents = [{"role": "user", "parts": [{"text": f"í™˜ì ì¦ìƒ: {messages[-1]['content']}"}]}]
    
    payload = {
        "system_instruction": {"parts": [{"text": system_prompt}]},
        "contents": formatted_contents
    }
    
    try:
        response = requests.post(url, json=payload)
        return response.json()['candidates'][0]['content']['parts'][0]['text']
    except Exception as e:
        return f"ìƒì„± ì˜¤ë¥˜: {e}"

# --- ë©”ì¸ í™”ë©´ ---
st.set_page_config(page_title="ë°”ë¥¸ ì•½ì´ˆ ì°¾ê¸°", page_icon="ğŸŒ¿")
st.title("ğŸŒ¿ ì¦ìƒë³„ ì•½ì´ˆ ì²˜ë°© (ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ)")

# ê°„ë‹¨ ë¡œê·¸ì¸
if "patient_id" not in st.session_state:
    st.text_input("ì‚¬ìš©ì ì´ë¦„", key="input_id")
    if st.session_state.input_id:
        st.session_state.patient_id = st.session_state.input_id
        st.rerun()
    st.stop()

# ëŒ€í™”ì°½
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë””ê°€ ë¶ˆí¸í•˜ì‹ ê°€ìš”? ì¦ìƒì„ ë§ì”€í•´ì£¼ì‹œë©´ ë”± ë§ëŠ” ì•½ì´ˆë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤."}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë°°ê°€ ì•„í”„ê³  ì„¤ì‚¬ê°€ ë‚˜ìš”)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    
    with st.chat_message("assistant"):
        status = st.status("ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ë’¤ì§€ëŠ” ì¤‘...", expanded=True)
        
        # 1. ê²€ìƒ‰ (DBì—ì„œ ë°”ë¡œ ê°€ì ¸ì˜¤ê¸°)
        retrieved_herbs = retrieve_context(prompt)
        status.write("âœ… ì•½ì´ˆ ë°ì´í„° í™•ë³´ ì™„ë£Œ!")
        
        # ë””ë²„ê¹…ìš©: ì‹¤ì œë¡œ ë­˜ ê°€ì ¸ì™”ëŠ”ì§€ ëˆˆìœ¼ë¡œ í™•ì¸ (ì¤‘ìš”!)
        with st.expander("ğŸ¤– AIê°€ ì°¾ì•„ë‚¸ í›„ë³´ ì•½ì´ˆë“¤ (í´ë¦­í•´ì„œ í™•ì¸)"):
            st.text(retrieved_herbs)
            
        # 2. ì§„ë‹¨ ìƒì„±
        status.write("ğŸ“ ì²˜ë°©ì „ ì‘ì„± ì¤‘...")
        diagnosis = generate_diagnosis(st.session_state.messages, retrieved_herbs)
        status.update(label="ì§„ë‹¨ ì™„ë£Œ", state="complete", expanded=False)
        
        st.markdown(diagnosis)
        
        # ì €ì¥ (ì„ íƒ ì‚¬í•­)
        if hasattr(db, 'save_diagnosis'):
            db.save_diagnosis(st.session_state.patient_id, prompt, "ì•½ì´ˆ ì²˜ë°©", diagnosis[:200])

    st.session_state.messages.append({"role": "assistant", "content": diagnosis})
